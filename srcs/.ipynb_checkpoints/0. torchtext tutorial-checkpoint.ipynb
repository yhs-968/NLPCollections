{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "- A Tutorial on Torchtext\n",
    "    - [blog post](http://anie.me/On-Torchtext/)\n",
    "    - [full code](https://github.com/mjc92/TorchTextTutorial/blob/master/01.%20Getting%20started.ipynb)\n",
    "- [torchtext(Github)](https://github.com/pytorch/text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'ice', 'creams', '.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# Define a tokenizer\n",
    "spacy_en = spacy.load('en')\n",
    "def spacy_tokenize(text):\n",
    "    '''A tokenizer function'''\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]\n",
    "\n",
    "spacy_tokenize('I love ice creams.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Field(a preprocessor class) and Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequential': True, 'use_vocab': True, 'init_token': '<sos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'fix_length': None, 'tensor_type': <class 'torch.LongTensor'>, 'preprocessing': None, 'postprocessing': None, 'lower': True, 'tokenize': <function spacy_tokenize at 0x7fb786a85598>, 'include_lengths': False, 'batch_first': False, 'pad_token': '<pad>', 'pad_first': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nuse_vocab: if False, integer indices, instead of vocabulary,\\nis used as inputs\\nlower: decapitalize all words\\ninit_token, eos_token: SOS, EOS tokens\\nfix_length: if specified, input lengths are fixed\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext import data, datasets\n",
    "\n",
    "# data.Field: a preprocessor class\n",
    "CORPUS = data.Field(sequential=True,\n",
    "                    tokenize=spacy_tokenize,\n",
    "                    lower=True,\n",
    "                    use_vocab=True,\n",
    "                   init_token = '<sos>',\n",
    "                   eos_token = '<eos>')\n",
    "\n",
    "print(vars(CORPUS))\n",
    "\n",
    "'''\n",
    "use_vocab: if False, integer indices, instead of vocabulary,\n",
    "is used as inputs\n",
    "lower: decapitalize all words\n",
    "init_token, eos_token: SOS, EOS tokens\n",
    "fix_length: if specified, input lengths are fixed\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = data.TabularDataset(\n",
    "    path ='../data/wiki.nlp.history.txt',\n",
    "    format='tsv',\n",
    "    fields=[('src', CORPUS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(sents): 15\n",
      "First sentence in the corpus: ['the', 'history', 'of', 'nlp', 'generally', 'started', 'in', 'the', '1950s', ',', 'although', 'work', 'can', 'be', 'found', 'from', 'earlier', 'periods', '.', 'in', '1950', ',', 'alan', 'turing', 'published', 'an', 'article', 'titled', '\"', 'computing', 'machinery', 'and', 'intelligence', '\"', 'which', 'proposed', 'what', 'is', 'now', 'called', 'the', 'turing', 'test', 'as', 'a', 'criterion', 'of', 'intelligence', '.']\n",
      "N(tokens) in the first sentence: 49\n"
     ]
    }
   ],
   "source": [
    "# the number of sentences in the corpus\n",
    "print('N(sents): %i' % len(corpus))\n",
    "# \n",
    "print('First sentence in the corpus: %s' % vars(corpus[0])['src'])\n",
    "print('N(tokens) in the first sentence: %i' %\n",
    "      len(vars(corpus[0])['src']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34\n",
      "34 34\n",
      "385\n",
      "Top 50 frequent words: [(',', 60), ('the', 39), ('of', 33), ('.', 26), ('-', 21), ('a', 16), ('in', 15), ('and', 15), ('to', 13), ('\"', 12), ('(', 12), (')', 12), ('systems', 10), ('for', 9), ('machine', 8), ('data', 8), ('which', 7), ('translation', 7), ('learning', 7), ('more', 6), ('that', 6), ('was', 6), ('research', 6), ('were', 6), ('language', 6), ('many', 6), ('models', 6), ('nlp', 5), ('as', 5), ('into', 5), (']', 5), ('however', 5), ('on', 5), ('has', 5), ('results', 5), ('is', 4), ('real', 4), ('when', 4), ('statistical', 4), ('developed', 4), ('with', 4), ('written', 4), ('are', 4), ('algorithms', 4), ('such', 4), ('input', 4), ('annotated', 4), ('generally', 3), ('be', 3), ('from', 3)]\n",
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "# Build a Vocab(vocabulary) for the corpus\n",
    "CORPUS.build_vocab(corpus,\n",
    "                  max_size = 30,\n",
    "                  min_freq = 3)\n",
    "'''\n",
    "max_size: the maximum # of words for the vocabulary\n",
    "min_freq: the minimum threshold for including a words in the vocabulary\n",
    "\n",
    "These condtions only apply to CORPUS.vocab.itos, CORPUS.vocab.stoi,\n",
    "and is ignored in CORPUS.vocab.freqs\n",
    "\n",
    "'''\n",
    "# vocabulary size\n",
    "print('Vocabulary size: %i' % len(CORPUS.vocab))\n",
    "# Size of for itos, stoi mapping(identical to the vocab size)\n",
    "print(len(CORPUS.vocab.itos), len(CORPUS.vocab.stoi))\n",
    "\n",
    "# frequency for *all* of the words appearing in the corpus\n",
    "# filtering conditions(max_size, min_freq) are ignored here.\n",
    "print(len(CORPUS.vocab.freqs))\n",
    "print('Top 50 frequent words: %s' % CORPUS.vocab.freqs.most_common(50))\n",
    "\n",
    "# unknown words are automatically dealt\n",
    "print(CORPUS.vocab.itos[CORPUS.vocab.stoi['sdfUAWBHruhq23']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pretrained Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Load pretrained word embeddings\n",
    "2. Build the vocabulary based on the pretrained embeddings\n",
    "\n",
    "    - Downloads the vector, to the *current_folder/.vector_cache* by default, if necessary\n",
    "        - The vector cache directory can be specified by specifying `cache` explicitly.\n",
    "        - Reference: [1](https://github.com/pytorch/text/blob/master/test/language_modeling.py), [2](https://github.com/pytorch/text/blob/master/torchtext/vocab.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import FastText\n",
    "import os\n",
    "FT = data.Field()\n",
    "corpus_path = '../data/wiki.nlp.history.txt'\n",
    "vector_cache_path = os.path.join(os.path.expanduser('~'), 'torchtext_data/.vector_cache')\n",
    "lm = datasets.LanguageModelingDataset(path = corpus_path, text_field = FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Embeddings**********\n",
      "\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "-0.0653 -0.0930 -0.0176  ...   0.1664 -0.1308  0.0354\n",
      "          ...             ⋱             ...          \n",
      "-0.0131  0.1322 -0.1948  ...  -0.1957  0.3368  0.2303\n",
      "-0.1493  0.2157  0.1882  ...   0.3233  0.3822 -0.0868\n",
      "-0.1382  0.2134  0.2215  ...   0.4661  0.2843 -0.1336\n",
      "[torch.FloatTensor of size 418x300]\n",
      "\n",
      "Vocabulary size: 418\n",
      "Embeeding dimension: 300\n"
     ]
    }
   ],
   "source": [
    "FT.build_vocab(lm, vectors = FastText(language = 'en',\n",
    "                                      cache = vector_cache_path))\n",
    "# Embedding Matrix(PyTorch FloatTensor)\n",
    "print('*' * 10 + 'Embeddings' + '*' * 10)\n",
    "print(FT.vocab.vectors)\n",
    "n, d = FT.vocab.vectors.size()\n",
    "print('Vocabulary size: %i' % n)\n",
    "print('Embeeding dimension: %i' % d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the pretrained word embeddings into a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "-0.0653 -0.0930 -0.0176  ...   0.1664 -0.1308  0.0354\n",
       "          ...             ⋱             ...          \n",
       "-0.0131  0.1322 -0.1948  ...  -0.1957  0.3368  0.2303\n",
       "-0.1493  0.2157  0.1882  ...   0.3233  0.3822 -0.0868\n",
       "-0.1382  0.2134  0.2215  ...   0.4661  0.2843 -0.1336\n",
       "[torch.FloatTensor of size 418x300]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "n, d = FT.vocab.vectors.size()\n",
    "emb = nn.Embedding(n, d)\n",
    "emb.weight.data.copy_(FT.vocab.vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
