{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, wordpunct_tokenize\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "def build_vocab(corpus, top_k = None):\n",
    "    '''\n",
    "    Builds a vocabulary, using the words in the corpus\n",
    "    \n",
    "    Args:\n",
    "        corpus: string of text.\n",
    "        top_k: the number of words to be included in the vocabulary, including the special tokens:\n",
    "        \"UNK(unknown)\", \"_BEGIN_(beginning of a sentence)\", \"_END_(end of a sentence)\"\n",
    "        \n",
    "    Returns:\n",
    "        word2id: dictionary of (word, id) pairs\n",
    "        id2word: list of words in the vocabulary\n",
    "    '''\n",
    "    if type(top_k) == int:\n",
    "        top_k -= 3\n",
    "    word_counts = Counter(wordpunct_tokenize(corpus)).most_common(top_k)\n",
    "    \n",
    "    id2word = sorted([word for word,count in word_counts]) + ['UNK','_BEGIN_','_END_']\n",
    "    word2id = {word: i for i, word in enumerate(id2word)}\n",
    "    \n",
    "    return word2id, id2word\n",
    "\n",
    "def sents2id(corpus, top_k = None, case_sensitive = False):\n",
    "    '''Tokenizes the whole corpus into sentences, mapping the words to corresponding indices.\n",
    "    \n",
    "    Args:\n",
    "        corpus: string.\n",
    "        \n",
    "    Returns:\n",
    "        sents_list: List of sentences, where each sentences are the list of word indices.\n",
    "        word2id: dictionary of (word, id) pairs\n",
    "        id2word: list of words in the vocabulary\n",
    "    '''\n",
    "    if not case_sensitive:\n",
    "        corpus = corpus.lower()\n",
    "    word2id, id2word = build_vocab(corpus, top_k)\n",
    "    sents = sent_tokenize(corpus)\n",
    "    \n",
    "    sents_list = []\n",
    "    for i in range(len(sents)):\n",
    "        sent = wordpunct_tokenize(sents[i])\n",
    "        sent = [word2id[word] if word in word2id else word2id['UNK'] for word in sent]\n",
    "        sent = [word2id['_BEGIN_']] + sent + [word2id['_END_']]\n",
    "        sents_list.append(sent)\n",
    "        \n",
    "    return sents_list, word2id, id2word\n",
    "\n",
    "def id2sents(sents):\n",
    "    '''Returns the string representation of the sentences, where sentences is a list of sentences\n",
    "    and each sentences are lists of word ids.\n",
    "    \n",
    "    Args:\n",
    "        sents: a list of word ids in the dictionary\n",
    "        \n",
    "    Returns:\n",
    "        sents_str: string representation of sentences.\n",
    "    '''\n",
    "    \n",
    "    return ' '.join([id2word[i_word] for i_word in chain(*sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = 'Deep learning (also known as deep structured learning or hierarchical learning) \\\n",
    "is part of a broader family of machine learning methods based on learning data representations, \\\n",
    "as opposed to task-specific algorithms. Learning can be supervised, partially supervised or unsupervised.\\\n",
    " Some representations are loosely based on interpretation of information processing and communication patterns \\\n",
    " in a biological nervous system, such as neural coding that attempts to define a relationship between various \\\n",
    " stimuli and associated neuronal responses in the brain. Research attempts to create efficient systems to \\\n",
    " learn these representations from large-scale, unlabeled data sets. Deep learning architectures such as \\\n",
    " deep neural networks, deep belief networks and recurrent neural networks have been applied to fields \\\n",
    " including computer vision, speech recognition, natural language processing, audio recognition, social \\\n",
    " network filtering, machine translation, bioinformatics and drug design .where they produced results \\\n",
    " comparable to and in some cases superior to human experts.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48, 16, 21, 0, 5, 47, 8, 16, 39, 21, 28, 47, 21, 47, 47, 47, 25, 4, 47, 47, 25, 22, 21, 47, 10, 26, 21, 15, 33, 1, 8, 27, 43, 47, 2, 37, 47, 3, 49], [48, 21, 13, 47, 41, 1, 47, 41, 28, 47, 3, 49], [48, 36, 33, 47, 47, 10, 26, 47, 25, 18, 30, 6, 14, 29, 17, 4, 47, 47, 42, 1, 40, 8, 24, 47, 47, 9, 43, 47, 4, 32, 47, 47, 38, 6, 47, 47, 34, 17, 47, 47, 3, 49], [48, 47, 9, 43, 47, 47, 47, 43, 20, 47, 33, 47, 19, 2, 35, 1, 45, 15, 47, 3, 49], [48, 16, 21, 7, 40, 8, 16, 24, 23, 1, 16, 12, 23, 6, 47, 24, 23, 47, 11, 47, 43, 47, 47, 47, 47, 1, 47, 31, 1, 47, 47, 30, 1, 47, 31, 1, 47, 47, 47, 1, 22, 44, 1, 47, 6, 47, 47, 3, 46, 47, 47, 47, 47, 43, 6, 17, 36, 47, 47, 43, 47, 47, 3, 49]]\n",
      "_BEGIN_ deep learning ( also UNK as deep structured learning or UNK learning UNK UNK UNK of a UNK UNK of machine learning UNK based on learning data representations , as opposed to UNK - specific UNK . _END_ _BEGIN_ learning can UNK supervised , UNK supervised or UNK . _END_ _BEGIN_ some representations UNK UNK based on UNK of information processing and communication patterns in a UNK UNK system , such as neural UNK UNK attempts to UNK a relationship UNK UNK stimuli and UNK UNK responses in UNK UNK . _END_ _BEGIN_ UNK attempts to UNK UNK UNK to learn UNK representations UNK large - scale , unlabeled data UNK . _END_ _BEGIN_ deep learning architectures such as deep neural networks , deep belief networks and UNK neural networks UNK been UNK to UNK UNK UNK UNK , UNK recognition , UNK UNK processing , UNK recognition , UNK UNK UNK , machine translation , UNK and UNK UNK . where UNK UNK UNK UNK to and in some UNK UNK to UNK UNK . _END_\n",
      "{'opposed': 27, '(': 0, 'data': 15, 'system': 42, 'scale': 35, 'specific': 37, 'been': 11, 'supervised': 41, 'in': 17, 'information': 18, '.': 3, 'some': 36, 'learn': 20, 'where': 46, 'responses': 34, '-': 2, 'unlabeled': 45, 'networks': 23, 'translation': 44, ',': 1, 'architectures': 7, 'can': 13, 'neural': 24, 'structured': 39, 'also': 5, 'to': 43, 'patterns': 29, 'UNK': 47, 'recognition': 31, 'such': 40, 'attempts': 9, 'large': 19, 'processing': 30, 'belief': 12, 'stimuli': 38, 'based': 10, 'of': 25, 'on': 26, 'representations': 33, 'or': 28, 'machine': 22, 'and': 6, 'communication': 14, 'deep': 16, '_END_': 49, 'a': 4, 'as': 8, 'learning': 21, '_BEGIN_': 48, 'relationship': 32}\n",
      "\n",
      "['(', ',', '-', '.', 'a', 'also', 'and', 'architectures', 'as', 'attempts', 'based', 'been', 'belief', 'can', 'communication', 'data', 'deep', 'in', 'information', 'large', 'learn', 'learning', 'machine', 'networks', 'neural', 'of', 'on', 'opposed', 'or', 'patterns', 'processing', 'recognition', 'relationship', 'representations', 'responses', 'scale', 'some', 'specific', 'stimuli', 'structured', 'such', 'supervised', 'system', 'to', 'translation', 'unlabeled', 'where', 'UNK', '_BEGIN_', '_END_']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sents_list, word2id, id2word = sents2id(corpus, top_k = 50)\n",
    "\n",
    "print(sents_list)\n",
    "print(id2sents(sents_list))\n",
    "\n",
    "print(word2id)\n",
    "print()\n",
    "\n",
    "print(id2word)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
