{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: [Official PyTorch Documentation](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "# Contents\n",
    "- What is PyTorch?\n",
    "- Autograd: automatic differentiation\n",
    "- Neural Networks\n",
    "- Training a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-4.5015e+05  4.5602e-41 -4.5015e+05\n",
      " 4.5602e-41  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.4682  0.6650  0.1787\n",
      " 0.4980  0.8678  0.8762\n",
      " 0.1675  0.9928  0.9055\n",
      " 0.7150  0.2290  0.3592\n",
      " 0.7683  0.3766  0.0659\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create a 5x3 matrix without initialization\n",
    "x = torch.Tensor(5,3)\n",
    "print(x)\n",
    "\n",
    "# Create a 5x3 matrix with random initialization\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "\n",
    "# size of the matrix\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5024  1.2250  1.0948\n",
      " 1.2774  0.9312  1.2939\n",
      " 0.5670  1.7859  1.7095\n",
      " 1.0135  0.8855  0.4436\n",
      " 1.0980  1.2328  0.8500\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.5024  1.2250  1.0948\n",
      " 1.2774  0.9312  1.2939\n",
      " 0.5670  1.7859  1.7095\n",
      " 1.0135  0.8855  0.4436\n",
      " 1.0980  1.2328  0.8500\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.5024  1.2250  1.0948\n",
      " 1.2774  0.9312  1.2939\n",
      " 0.5670  1.7859  1.7095\n",
      " 1.0135  0.8855  0.4436\n",
      " 1.0980  1.2328  0.8500\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "\n",
    "# Addition\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "\n",
    "# specify the output variable\n",
    "result = torch.Tensor(5,3)\n",
    "torch.add(x, y, out=result) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5024  1.2250  1.0948\n",
      " 1.2774  0.9312  1.2939\n",
      " 0.5670  1.7859  1.7095\n",
      " 1.0135  0.8855  0.4436\n",
      " 1.0980  1.2328  0.8500\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in-place addition\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.4682  0.6650  0.1787\n",
      " 0.4980  0.8678  0.8762\n",
      " 0.1675  0.9928  0.9055\n",
      " 0.7150  0.2290  0.3592\n",
      " 0.7683  0.3766  0.0659\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.6650\n",
      " 0.8678\n",
      " 0.9928\n",
      " 0.2290\n",
      " 0.3766\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy style indexing\n",
    "print(x)\n",
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful reference: [torch for numpy users](https://github.com/torch/torch7/wiki/Torch-for-Numpy-users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a Tensor from a Numpy array, the tensor changes automatically with respect to the numpy array that it was created from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.]\n",
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Numpy array to Tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending tensors for GPU operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.9706  1.8900  1.2735\n",
      " 1.7754  1.7991  2.1701\n",
      " 0.7345  2.7787  2.6149\n",
      " 1.7285  1.1146  0.8028\n",
      " 1.8663  1.6094  0.9159\n",
      "[torch.cuda.FloatTensor of size 5x3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](http://pytorch.org/tutorials/_images/Variable.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2,2), requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y` was created as a result of an operation, so it has a `grad_fn`, while `x` doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.AddConstantBackward object at 0x7f1f6baf39a8>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get the gradient function for the operation\n",
    "print(y.grad_fn)\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "<torch.autograd.function.MulConstantBackward object at 0x7f1f6baf3a98>\n",
      "<torch.autograd.function.MeanBackward object at 0x7f1f6baf3b88>\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)\n",
    "print(z.grad_fn)\n",
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing the values for the Gradients\n",
    "\n",
    "out.backward() # Compute the backward gradients\n",
    "# Equivalent to out.backward(torch.Tensor([1.0]))\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above follows since\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "out&=&\\frac{1}{4}\\sum_i{z_i}\\\\\n",
    "&=&\\frac{1}{4}\\sum_i{3(x_i+2)^2}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "and thus\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial out}{\\partial x_i}\\big|_{x_i=1}=\\frac{3}{2}(x_i+2)\\big|_{x_i=1}=4.5\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1505.7001\n",
      " 1027.0228\n",
      " -464.3599\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "  102.4000\n",
      " 1024.0000\n",
      "    0.1024\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more experiments\n",
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad = True)\n",
    "\n",
    "y = x * 2\n",
    "\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)\n",
    "\n",
    "gradients = torch.FloatTensor([0.1,1.0,0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](http://pytorch.org/tutorials/_images/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Call the initializer for nn.Module\n",
    "        super().__init__()\n",
    "        # 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # 6 input image channel, 16 output channels,\n",
    "        # 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Affine operations: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Define the Forward Propagation.\n",
    "        Backward propagation is automatically computed by\n",
    "        `backward()`\n",
    "        '''\n",
    "        # Max pooling over a (2,2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        # Max pooling over a (2,2) window(another way)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # Flatten the inputs into a long vector\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except for the batch\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Network()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the learnable parameters for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "  -0.0783 -0.0498 -0.2000 -0.0534  0.1625\n",
       "  -0.1639  0.1129 -0.0144 -0.0809  0.0134\n",
       "  -0.1503  0.0435 -0.0071  0.1132  0.1833\n",
       "  -0.1990 -0.0678  0.1160 -0.1810 -0.1036\n",
       "  -0.0938 -0.0642 -0.1794  0.1593 -0.0909\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "  -0.0594  0.1059 -0.0058 -0.0686 -0.0348\n",
       "  -0.0233  0.0198  0.0080  0.1953  0.0421\n",
       "  -0.1748  0.1489  0.0571 -0.1457  0.1001\n",
       "   0.0031 -0.1912 -0.0109  0.1601  0.1421\n",
       "  -0.1505 -0.0251 -0.0108 -0.0300 -0.0936\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "   0.0069 -0.0175  0.1387  0.1851  0.1259\n",
       "   0.0368  0.0861 -0.0230  0.0182 -0.1284\n",
       "  -0.1788  0.0103  0.0864  0.1087 -0.1620\n",
       "   0.1581  0.1422 -0.0124 -0.0825  0.0859\n",
       "   0.1813  0.0731 -0.0462 -0.0936 -0.0199\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "   0.1087 -0.0370  0.0073 -0.0077  0.1106\n",
       "   0.1147  0.1579 -0.0502 -0.0466  0.1046\n",
       "  -0.1723  0.1310  0.1192  0.1759  0.1375\n",
       "   0.0292 -0.1298  0.1214 -0.0326 -0.0791\n",
       "  -0.1063  0.0448  0.0511  0.1551 -0.1475\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "   0.0379  0.1788 -0.1487 -0.1802  0.0530\n",
       "   0.1067 -0.0173  0.1527  0.1495 -0.1433\n",
       "   0.1729 -0.0994  0.1825  0.0015  0.1886\n",
       "   0.1651 -0.1608  0.1250  0.1621 -0.1134\n",
       "   0.1653 -0.1342  0.1045  0.1292 -0.1764\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "  -0.0465  0.1768  0.1282 -0.1804 -0.1383\n",
       "   0.0854  0.1866 -0.0576 -0.0413 -0.1214\n",
       "  -0.0028  0.1326 -0.1576  0.0748 -0.0620\n",
       "   0.0664 -0.0181  0.1483  0.0718 -0.1126\n",
       "  -0.0025  0.1056 -0.0200 -0.1307  0.1950\n",
       " [torch.FloatTensor of size 6x1x5x5], Parameter containing:\n",
       " -0.1677\n",
       "  0.1579\n",
       "  0.0468\n",
       " -0.0024\n",
       " -0.0889\n",
       "  0.1088\n",
       " [torch.FloatTensor of size 6], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.3972 -5.8266  7.8890  1.1198  7.7061\n",
       "  -0.5065  4.5284 -1.5088  2.0815  7.3588\n",
       "  -3.2098 -1.4235 -0.8041 -7.5510 -2.0895\n",
       "  -2.8260 -0.2118  1.0007  7.4905  4.3364\n",
       "  -3.4388  4.0748 -1.1168  1.5042  0.9359\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.4326  6.0037  6.8765  8.0896 -1.9193\n",
       "   2.5021  1.0197  2.5207  2.9365  1.0374\n",
       "   3.9099 -6.5481  2.8656 -2.5740  7.7753\n",
       "  -3.9498  1.8639  0.6717 -6.5787 -3.5168\n",
       "   3.1114 -3.6518 -4.8132  6.7363  2.0540\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.7084 -1.4565 -5.5851 -4.9121 -5.4363\n",
       "  -6.2310  4.9740  3.5777 -3.8589  3.2637\n",
       "  -1.1698 -2.8419  5.2477  1.4665 -1.2163\n",
       "  -0.9577  3.3681  2.4219 -7.2757 -1.6055\n",
       "   7.8460  7.2638  1.2637 -2.8989  3.6530\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.4026  4.1241 -3.6549  7.0916  7.6995\n",
       "   1.0245 -2.8771  2.1350  5.0915  4.0657\n",
       "   7.4402 -4.0618 -6.7563  3.3463 -5.1508\n",
       "  -0.3596 -5.7489  4.6400  2.7850 -7.0788\n",
       "  -7.3016 -3.7134  4.9452  2.1232  4.3474\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.6434 -4.3074 -2.1732 -5.4477  0.4291\n",
       "   0.3425 -3.2236  7.1280  1.7064 -8.1217\n",
       "   1.4418  5.7100 -7.6640 -2.2544  7.5725\n",
       "   1.5605 -4.0699 -3.0527 -3.3810  0.2340\n",
       "  -6.4490  0.1795 -0.5883 -6.7780 -5.3179\n",
       " \n",
       " (0 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.2861 -6.0872  5.6363 -3.7530  6.0115\n",
       "   1.2136  4.7938 -0.1895  6.0436 -2.0671\n",
       "  -2.7142 -2.4662 -5.2088  4.3318  0.4842\n",
       "  -1.0851 -7.9567  6.2256  7.3109  4.9132\n",
       "   1.1472 -6.7796 -6.0785  4.5546 -1.4949\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.1717 -2.0444 -6.6409  7.9054 -5.8252\n",
       "   3.8848  6.7654  0.5189 -7.7762  2.3168\n",
       "  -5.2513  6.9407  4.3039 -7.2841  7.9290\n",
       "   5.7067  3.3068 -2.9922  4.7883 -0.6376\n",
       "   4.7448 -2.1712 -2.6972 -0.0472 -5.0258\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.2856  7.0574  3.4171 -4.6357  3.9042\n",
       "  -0.1036  4.7904 -4.1229 -4.3517 -0.5775\n",
       "   0.6547  6.4255  7.2753  5.1777 -0.8312\n",
       "  -3.4345  1.5158 -0.3825 -2.2508  4.7813\n",
       "   0.1476 -6.9479 -3.2345 -3.6559 -7.6800\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.1876 -6.3892 -0.7338 -5.1356  0.2584\n",
       "   3.3950  1.0414  1.5247  1.7995 -7.2963\n",
       "  -5.4619  0.8575  1.3420  5.5141 -7.9752\n",
       "   5.5260 -5.3062  5.1469 -2.4388  1.2430\n",
       "   5.3664 -2.3992  6.2838  7.1725 -0.8695\n",
       " \n",
       " (1 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.7154 -2.1325  6.1566 -1.5747 -2.7497\n",
       "   3.4575 -5.9630  5.6664  2.9403 -5.2291\n",
       "  -4.2402 -5.9306  3.4414 -5.1312 -6.2021\n",
       "   1.1011  3.3561  1.7866 -5.0951  4.6821\n",
       "  -1.5262 -0.5134  6.4140 -3.5750  0.9483\n",
       " \n",
       " (1 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.8377  3.7036 -0.4976  6.5422  3.0744\n",
       "   1.2944 -8.0982  5.0227 -4.3185  6.0105\n",
       "   0.2662  3.2599  1.3256 -7.7319  6.8992\n",
       "   6.2015 -5.7692  1.8707 -4.0508 -4.6701\n",
       "  -0.7465 -3.2568  3.4285  5.8562 -0.5344\n",
       " \n",
       " (1 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.7874 -0.3177  3.8239 -0.5457 -1.6552\n",
       "  -3.4414 -4.3746 -1.0983 -4.8832 -6.6047\n",
       "   5.6515  4.3497 -2.7204  5.4489 -3.2818\n",
       "   4.9835 -4.6703  1.6886 -0.4972 -0.9022\n",
       "  -6.5051  4.1249  7.7539  6.7788  7.3373\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.0575 -4.4462  4.5971  4.1748 -5.3668\n",
       "   7.2117  6.1864 -7.1597 -7.2811 -0.3190\n",
       "   1.1771  3.1323  1.8938  0.0588  3.5229\n",
       "  -8.0639  7.5311  3.6667 -0.2807 -3.7084\n",
       "   7.3839 -3.8785 -4.3392 -5.5972  4.8053\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.4643  3.3926  3.1150  1.5530  6.7498\n",
       "  -8.0540 -1.7904  6.1484 -2.6658 -6.3448\n",
       "   5.4508  0.6529 -7.1595 -8.0719 -3.1171\n",
       "   1.2562  2.0160 -7.7903  0.7366 -5.8929\n",
       "   2.3067  4.5032 -6.8371  7.8241  3.8929\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.9219 -4.3346  8.0446 -4.5498 -5.8822\n",
       "  -5.1215 -0.5612  5.2119  5.1532  7.2299\n",
       "   6.6688 -7.8749 -3.2483 -4.8748 -2.6842\n",
       "  -0.4634  7.9509  3.2745 -4.0714 -1.0086\n",
       "  -8.1263  1.9653 -6.3655  3.5635  8.1614\n",
       " \n",
       " (2 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.7441 -7.4608  2.1271  7.8823 -8.0598\n",
       "   5.8297 -1.1491 -0.8136  0.0249  6.7609\n",
       "   0.2491 -5.4030 -2.2770  1.9078 -4.4364\n",
       "  -6.2292 -4.9827  6.7532 -0.9757  6.8759\n",
       "  -5.5449 -3.1021 -0.1466 -3.7083  1.8683\n",
       " \n",
       " (2 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.8460  5.4946 -3.4865  5.7317 -1.0188\n",
       "   4.7439  7.0917 -7.1249  2.0042  0.7383\n",
       "   1.0277  6.9870  6.5763 -7.8211 -5.0111\n",
       "  -4.2122  1.5966  1.2076 -5.1672 -2.2171\n",
       "  -5.2566  5.7813 -5.3394 -0.9433 -2.5449\n",
       " \n",
       " (2 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.6310 -7.5550  5.0189 -7.3654  6.3837\n",
       "  -7.4144  0.7858  0.4914 -2.3105  5.5438\n",
       "   3.8277 -6.0812  1.9547  1.6038 -2.1089\n",
       "   7.2975 -5.3161  4.4826 -2.9353  7.4376\n",
       "   5.1087  3.7650 -5.8090  4.1231  4.3293\n",
       " ...   \n",
       "      ⋮ \n",
       " \n",
       " (13,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.2816  0.3615 -7.9120  3.1681  5.8193\n",
       "   0.5944  3.2049 -3.1031 -2.8391 -6.5806\n",
       "  -7.8810  5.8909  7.9984 -1.6261  6.9421\n",
       "   5.7945  4.7211  3.6343 -7.4851  6.7452\n",
       "   7.3124 -6.9180 -5.1105 -5.0690 -5.1694\n",
       " \n",
       " (13,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.6149 -7.1749  6.5430  6.6670 -1.8268\n",
       "   7.1866 -0.2425 -3.1234 -5.6556 -1.8140\n",
       "   5.6743  1.9854  5.2187  2.5069  1.4218\n",
       "   2.6503 -2.0729 -3.5397 -1.4402 -2.3642\n",
       "  -1.8851  0.7239  4.5360 -6.6656  3.1466\n",
       " \n",
       " (13,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.9342 -7.3915 -0.3841  2.5245  7.7945\n",
       "   5.6063  5.3030 -3.7305 -0.9807 -5.4481\n",
       "  -2.2735 -8.0593  5.0025  4.7867 -0.8667\n",
       "  -7.3883  3.9684  0.0078 -0.5271 -4.3910\n",
       "  -6.3296  2.8695 -4.9935  6.5446 -6.8741\n",
       " \n",
       " (13,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.8146  1.0892 -3.5038  1.3814 -1.3019\n",
       "  -1.5927  1.7510  6.8017  7.9228  5.5239\n",
       "  -6.8949 -5.9485  7.0213  5.0724 -5.9826\n",
       "  -7.1789  7.4600 -0.3924 -5.9449  6.8937\n",
       "  -3.8632  6.3657  6.0042 -7.1063  0.0845\n",
       " \n",
       " (13,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.6093 -0.0779  6.5478  0.2988  2.7317\n",
       "  -4.6748 -7.3493  5.4996  1.8998 -7.4105\n",
       "  -5.1703  0.1207  5.3538 -4.4516  4.0458\n",
       "   2.9137 -6.0311  0.9119 -0.0425 -4.3672\n",
       "   2.6117  0.5428  1.7816 -4.8570 -2.9127\n",
       " \n",
       " (13,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.3168 -1.6264  7.9445  3.6759 -0.7342\n",
       "   0.1286 -3.1347 -0.5398 -0.7385 -3.6136\n",
       "  -1.7767  4.1768 -4.4987 -2.7071 -5.5007\n",
       "   2.5424  2.1847  6.5623 -5.3404 -4.1986\n",
       "  -7.8546  2.2405 -2.9009 -0.1642 -5.6595\n",
       "      ⋮ \n",
       " \n",
       " (14,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.4297 -6.2509 -6.1609 -3.0918 -6.9968\n",
       "  -6.2767  0.1649 -6.0015  4.7755  0.7110\n",
       "   2.2518 -6.4884 -7.7829  7.8084 -1.6719\n",
       "   5.7635 -1.8286  5.3287  1.8437 -1.8024\n",
       "   1.4541  1.9280 -5.5079 -2.7751  6.4425\n",
       " \n",
       " (14,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.6219  1.8989  0.5431  5.4215 -5.6353\n",
       "   6.9854 -5.8421 -4.6469 -6.6589 -3.8165\n",
       "  -5.1133 -3.3501  1.2662  3.9800 -6.7731\n",
       "  -1.9787 -3.6922  7.7505 -5.4102 -3.7492\n",
       "  -4.6268 -7.9994  2.2055  0.3163  5.6265\n",
       " \n",
       " (14,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.3192 -2.3220  4.2322  3.8141 -5.9474\n",
       "  -3.4086 -3.8696 -7.1129  4.3850  1.3827\n",
       "  -4.0839  6.8487 -8.1133 -7.9949  4.8914\n",
       "  -7.8433 -0.1619 -1.4450 -2.4998  0.5755\n",
       "  -1.6076 -2.8729 -7.6868 -3.4515 -1.6895\n",
       " \n",
       " (14,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.0487 -0.5553  4.6784 -1.1902 -0.4528\n",
       "  -4.9227 -0.3826  2.1932 -0.7569 -4.4228\n",
       "   0.1152  0.5390  1.2609 -3.5737 -7.2747\n",
       "   1.4465  6.3654  5.6426 -6.4367 -5.2867\n",
       "   2.6301  1.6943 -1.2267 -2.2121  3.2072\n",
       " \n",
       " (14,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.2965 -4.8928  0.1044  2.1286 -0.0045\n",
       "  -3.5955  4.6109 -6.4347 -0.0240 -0.2148\n",
       "  -0.6816  2.3024  0.6453 -6.3149 -0.6397\n",
       "  -7.8360 -5.2710 -6.0761  3.8814  7.8770\n",
       "   7.8126 -3.7118  7.8607  3.3576 -4.3803\n",
       " \n",
       " (14,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.0313  0.4497 -5.3015 -3.0833  0.2114\n",
       "   4.9012 -3.9357  5.4177 -1.4839 -2.2425\n",
       "  -2.8180 -3.9109 -0.8320  4.7552  5.7931\n",
       "  -3.5546  3.7875  1.3507 -1.6470  8.0909\n",
       "   7.5484 -3.6184  0.4832 -2.2104  0.7455\n",
       "      ⋮ \n",
       " \n",
       " (15,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.6963  4.3835 -2.0803  2.3752  0.5911\n",
       "   6.7289 -0.3935  4.8664 -2.5061 -2.5830\n",
       "  -7.8504  4.7107  7.7370  7.3852  5.1602\n",
       "   7.4564 -1.2249  5.3441 -8.0985  0.9617\n",
       "   5.3681 -4.6720  0.9320 -3.9333 -2.9954\n",
       " \n",
       " (15,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.3060 -8.1471  3.5866 -2.7485  6.2598\n",
       "   6.4560 -1.2556  3.6573  0.6645 -3.9479\n",
       "   3.9236 -6.4937 -0.9598 -0.8860 -3.4370\n",
       "   6.8880  7.2248  8.0792 -2.2189  1.7118\n",
       "  -2.6156 -6.5521  4.7621  4.1040 -7.0622\n",
       " \n",
       " (15,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.9852 -2.3027 -2.0442  2.7252  1.6905\n",
       "   1.1509 -3.0142  1.3361 -3.1361 -4.4139\n",
       "  -2.9278  1.8693  4.8195 -6.4674  4.4221\n",
       "   3.4224 -4.9522  7.2822 -6.6117 -1.3709\n",
       "   1.7080 -5.1377  0.6818  4.6065 -2.1487\n",
       " \n",
       " (15,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.0395  1.4566  1.6854  0.0709 -4.0332\n",
       "  -7.5249 -1.1286 -5.0510  0.9163 -5.0496\n",
       "  -1.1607 -7.3627  5.9210  3.8107 -5.5681\n",
       "   7.9212  0.1426  6.8060  7.2388 -2.5420\n",
       "   3.8236  4.4561 -2.7770 -3.8910  3.7471\n",
       " \n",
       " (15,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.0537  5.3384 -3.4799  7.8365  3.2206\n",
       "   7.7255  4.9722  7.2400  1.2625 -7.0962\n",
       "   5.4160  6.0686 -2.7475 -7.7302  0.5217\n",
       "   0.8736 -1.5034  3.0933  7.3444  3.8927\n",
       "   4.1653  6.0134 -0.6629 -7.5761 -2.2312\n",
       " \n",
       " (15,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.6470  1.0449 -5.1735  3.5869  3.6382\n",
       "  -2.5748  0.7175 -0.0256  2.3235  5.7273\n",
       "   7.2136 -4.0451 -1.4821 -3.5122  0.1486\n",
       "  -2.7994 -1.0485 -6.6208 -7.2140 -1.8528\n",
       "  -2.6315 -0.4553 -5.3894 -2.6186 -1.4767\n",
       " [torch.FloatTensor of size 16x6x5x5], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -1.2923\n",
       "   4.5101\n",
       "  -7.2299\n",
       "  -4.1583\n",
       "   0.1037\n",
       "  -7.6403\n",
       "   4.4577\n",
       "  -0.2737\n",
       "  -5.8098\n",
       "   4.6837\n",
       "   3.8571\n",
       "   7.6702\n",
       "  -5.6683\n",
       "  -3.6004\n",
       "   5.2204\n",
       "   3.5059\n",
       " [torch.FloatTensor of size 16], Parameter containing:\n",
       "  3.2062e-03 -2.1750e-02  4.4880e-02  ...   2.3948e-02 -3.7431e-02 -2.7628e-02\n",
       " -1.3225e-02  3.8238e-02 -4.1708e-02  ...  -1.0549e-02  4.2127e-02 -3.9870e-02\n",
       "  1.8312e-02  5.3442e-03 -2.8375e-02  ...   2.2778e-02 -2.3600e-02 -3.6888e-02\n",
       "                 ...                   ⋱                   ...                \n",
       "  4.3868e-02  4.2062e-02  2.2519e-02  ...   5.8862e-03 -3.3998e-02 -4.5247e-02\n",
       "  2.9229e-03  4.6886e-02 -9.6117e-03  ...   4.0125e-03  3.3430e-02  1.7380e-02\n",
       " -1.6818e-02 -3.0149e-02  3.0862e-03  ...  -3.7437e-02  3.9797e-02 -1.8888e-03\n",
       " [torch.FloatTensor of size 120x400], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   0.1018\n",
       "   4.8272\n",
       "  -0.3931\n",
       "   0.9863\n",
       "  -1.2942\n",
       "   0.0778\n",
       "  -3.8629\n",
       "  -0.0265\n",
       "  -4.0994\n",
       "   1.3722\n",
       "   4.2926\n",
       "   0.3267\n",
       "   3.2895\n",
       "  -1.9851\n",
       "   1.3801\n",
       "  -0.3690\n",
       "  -4.5021\n",
       "   4.8569\n",
       "   2.2704\n",
       "   4.1363\n",
       "  -0.2014\n",
       "   3.0355\n",
       "   4.7133\n",
       "  -1.6244\n",
       "   3.8064\n",
       "   0.8721\n",
       "  -4.6407\n",
       "  -1.2153\n",
       "   4.6429\n",
       "   4.2491\n",
       "  -4.1978\n",
       "  -1.7055\n",
       "  -2.1561\n",
       "  -0.6571\n",
       "   2.9773\n",
       "  -0.4187\n",
       "   4.6214\n",
       "  -0.4703\n",
       "   1.0357\n",
       "  -0.9403\n",
       "   2.9137\n",
       "  -2.1817\n",
       "   2.0962\n",
       "  -2.5315\n",
       "   4.9808\n",
       "  -1.8479\n",
       "   4.9812\n",
       "  -4.0904\n",
       "   2.4772\n",
       "   4.7141\n",
       "   4.6127\n",
       "   4.8403\n",
       "  -0.4210\n",
       "   4.1374\n",
       "   4.8693\n",
       "  -1.1440\n",
       "  -3.8724\n",
       "  -2.8120\n",
       "  -0.3433\n",
       "  -4.2638\n",
       "   3.1299\n",
       "   2.9475\n",
       "   1.5631\n",
       "  -1.7172\n",
       "   3.7731\n",
       "  -3.2866\n",
       "   3.8893\n",
       "  -2.9562\n",
       "   1.6798\n",
       "   4.4882\n",
       "  -4.8486\n",
       "   0.5431\n",
       "  -3.2660\n",
       "   4.5722\n",
       "   4.9559\n",
       "  -0.3121\n",
       "   0.5253\n",
       "  -4.8298\n",
       "  -4.7531\n",
       "  -4.1706\n",
       "   4.5730\n",
       "   3.2506\n",
       "   2.7301\n",
       "  -3.9766\n",
       "  -0.8016\n",
       "   4.0224\n",
       "  -4.1341\n",
       "  -1.1093\n",
       "  -0.8358\n",
       "  -4.1067\n",
       "  -0.5804\n",
       "   2.0396\n",
       "   2.8985\n",
       "   0.9465\n",
       "   2.4147\n",
       "   2.3043\n",
       "  -4.7942\n",
       "  -1.4803\n",
       "   3.4990\n",
       "   0.5318\n",
       "  -4.6111\n",
       "  -3.2224\n",
       "  -4.0232\n",
       "   4.9553\n",
       "  -2.6412\n",
       "   4.6813\n",
       "   0.1621\n",
       "  -1.3903\n",
       "   4.0187\n",
       "   2.2236\n",
       "   1.4972\n",
       "   1.3671\n",
       "   0.5774\n",
       "   1.9122\n",
       "  -4.3815\n",
       "  -3.9646\n",
       "  -0.6305\n",
       "  -4.0416\n",
       "  -2.9416\n",
       "   0.1986\n",
       " [torch.FloatTensor of size 120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  2.4262  0.5946 -6.6844  ...   4.3632  0.7960 -5.6738\n",
       "  0.5363 -1.3199  6.9992  ...   7.0932  2.7841 -8.7933\n",
       "  0.8433  8.3609 -2.3700  ...   4.0268  2.5134  5.7894\n",
       "           ...             ⋱             ...          \n",
       " -2.6638  9.0534  8.2873  ...  -7.7801 -5.0082 -6.6488\n",
       " -2.0791 -4.2630  7.6333  ...   4.8312 -5.2148  5.1958\n",
       "  8.9262  5.4789 -7.5394  ...   2.5212  9.0802  8.2270\n",
       " [torch.FloatTensor of size 84x120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   3.7157\n",
       "   1.2613\n",
       "  -0.4242\n",
       "   7.5728\n",
       "  -1.1161\n",
       "  -5.5763\n",
       "   2.6417\n",
       "  -0.4334\n",
       "   4.8195\n",
       "   1.0347\n",
       "  -6.7021\n",
       "   7.9077\n",
       "   7.0097\n",
       "   7.8141\n",
       "  -4.2745\n",
       "   5.4493\n",
       "   4.0301\n",
       "  -2.0363\n",
       "  -3.1620\n",
       "  -2.6397\n",
       "   3.3689\n",
       "  -6.9946\n",
       "  -5.5960\n",
       "  -5.2582\n",
       "   8.9239\n",
       "  -7.9822\n",
       "  -3.1116\n",
       "  -1.9806\n",
       "   1.6127\n",
       "  -5.9879\n",
       "   0.4485\n",
       "   6.5573\n",
       "   4.9537\n",
       "   8.6422\n",
       "  -4.3650\n",
       "  -2.7783\n",
       "   5.8509\n",
       "   2.5902\n",
       "   5.3363\n",
       "   6.1679\n",
       "   3.2773\n",
       "   0.6397\n",
       "  -1.1892\n",
       "  -4.9178\n",
       "  -7.0266\n",
       "  -2.6778\n",
       "  -8.1478\n",
       "  -4.9294\n",
       "   5.0845\n",
       "   0.7068\n",
       "  -1.6612\n",
       "   2.6383\n",
       "  -6.6364\n",
       "  -1.7668\n",
       "  -7.1959\n",
       "   8.4418\n",
       "  -3.3636\n",
       "  -5.7735\n",
       "   3.8311\n",
       "   4.7471\n",
       "  -8.6782\n",
       "  -3.1184\n",
       "  -8.1745\n",
       "   8.9975\n",
       "  -6.5096\n",
       "  -0.0614\n",
       "   4.8997\n",
       "  -0.8100\n",
       "  -2.9675\n",
       "  -1.3931\n",
       "   3.3032\n",
       "  -2.6559\n",
       "   0.3226\n",
       "  -7.0608\n",
       "   2.9242\n",
       "  -1.2638\n",
       "  -7.4676\n",
       "  -5.4783\n",
       "   8.6227\n",
       "   0.1484\n",
       "  -1.5808\n",
       "  -0.8689\n",
       "   4.6265\n",
       "   4.8187\n",
       " [torch.FloatTensor of size 84], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -0.0052 -0.0542 -0.0573 -0.0285  0.0154  0.0473 -0.0390  0.0560  0.0994  0.0855\n",
       " -0.0294 -0.0779 -0.0047 -0.0702  0.0059 -0.0460  0.1040  0.0238 -0.0765  0.0971\n",
       " -0.0238  0.0896  0.0779  0.0024  0.0904 -0.0347 -0.0958 -0.0782 -0.0161 -0.0216\n",
       " -0.0424  0.0569  0.0592 -0.0433 -0.0952 -0.0417  0.0153  0.0974 -0.0766  0.1084\n",
       "  0.0478 -0.0767  0.0051  0.0904 -0.0380 -0.0211  0.1083 -0.1031 -0.0327  0.0587\n",
       " -0.0418  0.1052 -0.0289 -0.0907 -0.0482 -0.0539  0.0503 -0.0630 -0.0702  0.0858\n",
       " -0.0823  0.1013  0.1027 -0.0668  0.0705  0.0868 -0.0768 -0.0935 -0.0006 -0.0326\n",
       " -0.0118 -0.0398 -0.0019  0.1016 -0.0200  0.0425  0.1044 -0.0846 -0.0028  0.0578\n",
       " -0.0235  0.0877  0.0087 -0.0089 -0.1058 -0.0929  0.0922 -0.0734  0.0169  0.0367\n",
       "  0.0167 -0.1043 -0.0483  0.0438 -0.0206 -0.0186 -0.0107 -0.0014 -0.0821 -0.0979\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.0045 -0.0445 -0.0585 -0.0117 -0.0369  0.0685  0.1054  0.0451  0.0738 -0.0180\n",
       " -0.0457 -0.0532  0.0174 -0.0472  0.0297  0.0647  0.1088  0.0670 -0.0308 -0.0672\n",
       " -0.0572 -0.0684  0.0689  0.0297  0.0775  0.0479 -0.0697 -0.0193 -0.0310 -0.0524\n",
       "  0.0586 -0.0657 -0.0447  0.0096  0.0434 -0.0936  0.0238  0.0759  0.0139  0.0904\n",
       " -0.0109  0.0116 -0.0348  0.0721  0.0783 -0.0837 -0.0541 -0.0328 -0.0230  0.0085\n",
       "  0.0383 -0.0859 -0.0774  0.0143 -0.0303  0.0158  0.0884  0.0716 -0.0268  0.0408\n",
       "  0.0773 -0.0523  0.0783 -0.0574  0.0101  0.0288  0.0284  0.0941 -0.0517 -0.0970\n",
       "  0.0168 -0.0450  0.0583  0.0486 -0.0940  0.0128  0.0309 -0.0728  0.0398 -0.0691\n",
       "  0.0445 -0.0661 -0.0881 -0.1034  0.0359  0.0724 -0.0733 -0.0909  0.0039 -0.0818\n",
       " -0.0445 -0.1023 -0.0267  0.0251 -0.0704  0.0658 -0.0961 -0.0418 -0.0957  0.0040\n",
       " \n",
       " Columns 20 to 29 \n",
       " -0.0029 -0.0792 -0.0108 -0.0359 -0.0517  0.0205 -0.0500  0.0344  0.0925  0.0081\n",
       " -0.0961 -0.0045  0.0722 -0.0092  0.0935  0.0967 -0.1013  0.1050 -0.0879  0.1032\n",
       " -0.0359 -0.0670  0.0449  0.0319 -0.0504  0.0724 -0.0439 -0.0743  0.0577  0.0835\n",
       " -0.0526 -0.0916  0.0455 -0.0212 -0.0008  0.0155  0.0493  0.0073  0.0082  0.0205\n",
       " -0.0365  0.0018  0.0693  0.0473 -0.0480 -0.0524  0.0313 -0.0879 -0.0944  0.0932\n",
       " -0.0765  0.0453 -0.0881  0.0790  0.0998  0.0724 -0.0665  0.0466  0.0102  0.0583\n",
       "  0.0958  0.0765 -0.0204 -0.0560 -0.0869 -0.0711  0.0682 -0.0087 -0.0456  0.0695\n",
       " -0.0722  0.1077  0.0480  0.0280  0.1068  0.0658 -0.0539  0.0455 -0.1067  0.1056\n",
       " -0.0966 -0.1037  0.0521 -0.0116  0.0155 -0.0841 -0.0879 -0.0675 -0.0039 -0.0146\n",
       " -0.0060  0.0837 -0.0492  0.0332  0.0696  0.0948  0.0090  0.0965 -0.0840  0.0366\n",
       " \n",
       " Columns 30 to 39 \n",
       " -0.0616  0.1067 -0.1064 -0.0622  0.0548 -0.0658 -0.0399 -0.0042  0.0252 -0.1075\n",
       " -0.0054  0.0313 -0.0289  0.0646 -0.0224  0.0563 -0.1057 -0.0790  0.0114  0.0289\n",
       " -0.0937 -0.0221  0.1045 -0.0564  0.0713  0.0097 -0.0393 -0.0661  0.0409 -0.0667\n",
       "  0.0720 -0.0878  0.0499  0.0182  0.0858 -0.1042 -0.0057 -0.0177 -0.0520 -0.0424\n",
       " -0.0159  0.0166  0.0799  0.0159 -0.0238 -0.0595  0.0114  0.0291  0.0538 -0.0004\n",
       "  0.0728  0.1086 -0.0454 -0.0328  0.0897 -0.0963  0.1088 -0.0394  0.0414 -0.1026\n",
       "  0.1040  0.0872  0.0520 -0.0528  0.0014 -0.1035 -0.0672 -0.0599  0.0389  0.0186\n",
       "  0.0428 -0.0079 -0.0668 -0.0876 -0.0355 -0.0243 -0.0969 -0.0724  0.1075 -0.0080\n",
       " -0.0830  0.0335 -0.0993 -0.0592 -0.0815  0.0966 -0.0363  0.0776  0.0892 -0.0039\n",
       "  0.0193  0.0581  0.0789  0.0309  0.0342 -0.0084  0.0818 -0.0269  0.1037  0.0406\n",
       " \n",
       " Columns 40 to 49 \n",
       "  0.0751  0.0093  0.0079 -0.0319  0.1065 -0.0407  0.0614 -0.0214  0.1013 -0.0816\n",
       " -0.0243 -0.0852  0.0614 -0.0760  0.0637 -0.0923 -0.0579  0.0090  0.0306  0.0674\n",
       " -0.0740  0.0352  0.0992 -0.0078  0.0483 -0.0675 -0.1054 -0.0527  0.0273  0.0322\n",
       "  0.0976 -0.0018  0.0689 -0.0626  0.0962  0.0157  0.0461  0.0915  0.0087  0.0642\n",
       "  0.0161 -0.0237  0.0552  0.0504  0.0745 -0.0993  0.0270 -0.0525 -0.0712 -0.0501\n",
       "  0.0999 -0.0926  0.0248  0.0830  0.0703  0.0261 -0.0003  0.0774 -0.1080 -0.0365\n",
       " -0.1023  0.0720  0.0393  0.0179 -0.0508  0.0213 -0.0344 -0.0464 -0.0756 -0.0407\n",
       "  0.0552 -0.0298 -0.0976 -0.0848  0.1078  0.0108 -0.0715 -0.0143  0.0769  0.0523\n",
       "  0.0213 -0.1068  0.1075 -0.0928  0.0690  0.0208  0.0711  0.0517 -0.0150 -0.0651\n",
       "  0.0731  0.0692  0.0178 -0.0518 -0.0535 -0.0224 -0.0488 -0.0411 -0.0936 -0.1046\n",
       " \n",
       " Columns 50 to 59 \n",
       " -0.0678 -0.0627  0.0266 -0.0667  0.0112 -0.0771 -0.0264 -0.0466 -0.0950  0.0055\n",
       " -0.0273 -0.0644 -0.1061  0.0202 -0.0450 -0.0499  0.0330 -0.0143 -0.0833 -0.0869\n",
       " -0.0394  0.0537 -0.0494 -0.0515  0.0873 -0.0235 -0.0378 -0.0095  0.1028 -0.0303\n",
       "  0.0646 -0.0208  0.0545 -0.0354  0.0626  0.0872  0.1048 -0.0321 -0.0677  0.0605\n",
       " -0.1009 -0.0698 -0.0245  0.1085 -0.1045 -0.0677  0.0237  0.0620  0.0071 -0.0872\n",
       "  0.0593 -0.0504  0.0934  0.0734  0.0169  0.0648  0.0712  0.0254  0.0266  0.0069\n",
       "  0.0731  0.0932 -0.0235  0.0743 -0.0250  0.0162 -0.0397  0.0034 -0.0687 -0.0661\n",
       "  0.0274 -0.0240  0.0275  0.0005 -0.0967 -0.0739  0.0500 -0.0058  0.0010 -0.0720\n",
       "  0.0102  0.0791  0.0494 -0.0489 -0.0801  0.1000  0.0191  0.0432  0.0503  0.0781\n",
       " -0.1021  0.0013 -0.0062  0.0190 -0.0602 -0.0318  0.0448 -0.0490  0.0670 -0.0034\n",
       " \n",
       " Columns 60 to 69 \n",
       " -0.0682 -0.0466 -0.0410 -0.0769  0.0233  0.0463  0.0854  0.0550  0.1072 -0.0892\n",
       " -0.0977 -0.0489  0.0418 -0.0851  0.0778  0.0793 -0.0694 -0.0550  0.0513  0.0367\n",
       "  0.0342 -0.0755 -0.0855  0.1021  0.0762  0.1089 -0.0282 -0.0843  0.0620 -0.0915\n",
       "  0.1068  0.0113  0.1080 -0.0804  0.1016  0.0060 -0.0196  0.1086  0.0745  0.1035\n",
       "  0.0675 -0.0322 -0.0339  0.0566 -0.0133 -0.0288  0.0042 -0.0495 -0.0667  0.0826\n",
       "  0.0728  0.0918 -0.0304 -0.0423  0.1083  0.0725  0.1041 -0.1065 -0.0585 -0.0667\n",
       " -0.0585 -0.0072  0.0668 -0.1039  0.0938 -0.1018  0.0650 -0.0034  0.0184  0.0838\n",
       " -0.0711 -0.0459  0.1057 -0.0349  0.0106  0.0208  0.0296  0.0486 -0.0223  0.0277\n",
       "  0.0004 -0.0757  0.0038 -0.0405  0.0330 -0.0347 -0.0570  0.1065 -0.0777 -0.0799\n",
       " -0.0995 -0.1027 -0.0521  0.0779  0.1012 -0.0557  0.0698  0.0835  0.0525  0.0551\n",
       " \n",
       " Columns 70 to 79 \n",
       "  0.0055  0.0155 -0.0673  0.0471  0.0714 -0.0359  0.0721  0.0040  0.0759 -0.0816\n",
       "  0.0471  0.0986  0.1002 -0.1053  0.0327  0.0207  0.0087  0.0045 -0.0955  0.0290\n",
       "  0.0979 -0.0880  0.0940 -0.0170  0.0175 -0.0378  0.1064  0.0183  0.0886  0.0335\n",
       " -0.0312  0.0286 -0.0278 -0.0502  0.0177  0.1091 -0.0798  0.0520 -0.0856 -0.0695\n",
       " -0.0119  0.0390  0.1008 -0.0531  0.0264 -0.1055 -0.1070  0.1047  0.1082 -0.0578\n",
       " -0.0977 -0.1089 -0.0159  0.0681  0.0255  0.0913 -0.0587  0.0358  0.0022  0.0630\n",
       "  0.0590 -0.0729 -0.0747  0.0808 -0.0974 -0.0702  0.0038  0.1004  0.0834 -0.0219\n",
       " -0.0201 -0.0780 -0.0643 -0.0330 -0.0453  0.0286 -0.0039 -0.1053  0.0092 -0.0087\n",
       "  0.0602  0.0282  0.0474 -0.0202 -0.0384 -0.0086  0.0500  0.0855  0.0514 -0.0679\n",
       "  0.0843 -0.0738 -0.0246 -0.1013 -0.0417 -0.0979  0.0691 -0.0295 -0.0585  0.0494\n",
       " \n",
       " Columns 80 to 83 \n",
       "  0.0351  0.0434  0.0383  0.0008\n",
       "  0.0727 -0.0422 -0.0715 -0.0429\n",
       "  0.0184 -0.0766 -0.0944  0.0071\n",
       " -0.0775 -0.0709  0.0460  0.0909\n",
       "  0.0362  0.1032  0.0844  0.0170\n",
       " -0.0467  0.0299 -0.0727  0.0207\n",
       " -0.1007  0.0254  0.0374  0.0571\n",
       " -0.0228  0.0316  0.0654  0.0340\n",
       "  0.0389 -0.0541  0.0233 -0.0988\n",
       "  0.0136  0.0612 -0.1011  0.0991\n",
       " [torch.FloatTensor of size 10x84], Parameter containing:\n",
       "  0.0084\n",
       "  0.0713\n",
       "  0.0602\n",
       "  0.0471\n",
       "  0.0594\n",
       "  0.1091\n",
       "  0.1033\n",
       "  0.0072\n",
       " -0.0639\n",
       " -0.0765\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learnable parameters of a model\n",
    "params = list(net.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(len(params))\n",
    "for i in range(len(params)):\n",
    "    print(params[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0427  0.0369  0.0659 -0.0005  0.1279  0.1376  0.1158  0.0257 -0.0742 -0.0218\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward propagation\n",
    "input_ = Variable(torch.randn(1,1,32,32))\n",
    "output_ = net(input_)\n",
    "print(output_)\n",
    "\n",
    "# Zero the gradient buffers for all parameters\n",
    "net.zero_grad()\n",
    "\n",
    "# Backprop\n",
    "output_.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0427  0.0369  0.0659 -0.0005  0.1279  0.1376  0.1158  0.0257 -0.0742 -0.0218\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.1246\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_ = net(input_)\n",
    "# A dummy target labels\n",
    "labels = Variable(torch.arange(1,11))\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output_, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad b/f backprop\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n",
      "conv1.bias.grad a/f backprop\n",
      "Variable containing:\n",
      "-0.1719\n",
      " 0.0312\n",
      "-0.0041\n",
      " 0.0215\n",
      "-0.0281\n",
      " 0.0555\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad() # flush the gradient buffers\n",
    "\n",
    "print('conv1.bias.grad b/f backprop')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad a/f backprop')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights using naive python implementation of SGD\n",
    "\n",
    "```python\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the weights using optim package\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# create an optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate)\n",
    "\n",
    "# In your training loop\n",
    "optimizer.zero_grad() # flush\n",
    "output_ = net(input_)\n",
    "loss = criterion(output_, labels)\n",
    "loss.backward()\n",
    "optimizer.step() # 1-step update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using `torchvision`\n",
    "2. Define a CNN\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and normalize CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the CIFAR10 dataset into the memory.\n",
    "\n",
    "The output of torchvision datasets are PILImage images of range [0, 1].  \n",
    "We transform them to Tensors of normalized range [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "import os\n",
    "data_path = os.path.join(os.path.expanduser('~'),'data')\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ship  deer  bird   dog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8edd770eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN (\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear (400 -> 120)\n",
       "  (fc2): Linear (120 -> 84)\n",
       "  (fc3): Linear (84 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Takes a 3-channel image(RGB) as an input\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = CNN()\n",
    "net.cuda() # recursively send the parameters to use the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.173\n",
      "[1,  4000] loss: 1.835\n",
      "[1,  6000] loss: 1.688\n",
      "[1,  8000] loss: 1.594\n",
      "[1, 10000] loss: 1.518\n",
      "[1, 12000] loss: 1.465\n",
      "[2,  2000] loss: 1.380\n",
      "[2,  4000] loss: 1.375\n",
      "[2,  6000] loss: 1.345\n",
      "[2,  8000] loss: 1.336\n",
      "[2, 10000] loss: 1.300\n",
      "[2, 12000] loss: 1.270\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.1561 -1.0642  0.2958  0.7296  1.2599  0.0929  0.2500 -0.6106  0.0680 -1.3556\n",
       "-0.1569 -1.6040  1.6834  0.4872  0.1518  0.3568  0.5919 -0.5445 -0.6249 -1.1309\n",
       " 4.9688  1.0653 -0.9456 -2.8012 -0.1929 -5.0855 -3.8482 -2.9938  6.9887  1.5086\n",
       "-0.4304 -0.4528 -0.3092  0.3965  1.1427  1.1740 -1.7067  4.1144 -4.4349 -0.3419\n",
       "[torch.cuda.FloatTensor of size 4x10 (GPU 0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 6\n",
       " 5\n",
       " 8\n",
       " 7\n",
       "[torch.cuda.LongTensor of size 4 (GPU 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:    cat  ship  ship plane\n",
      "Predicted:    cat   car   car  ship\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+P/jyitvLuJHGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f534fa972b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the network on a small batch\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# Ground Truth\n",
    "print('Ground Truth: ',\n",
    "      ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# Predictions from the Network\n",
    "logits = net(Variable(images).cuda())\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "print('Predicted: ',\n",
    "      ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "# Test the network on the whole dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    logits = net(Variable(images).cuda())\n",
    "    _, predicted = torch.max(logits.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' %\n",
    "      (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 53 %\n",
      "Accuracy of   car : 66 %\n",
      "Accuracy of  bird : 36 %\n",
      "Accuracy of   cat : 18 %\n",
      "Accuracy of  deer : 44 %\n",
      "Accuracy of   dog : 64 %\n",
      "Accuracy of  frog : 68 %\n",
      "Accuracy of horse : 67 %\n",
      "Accuracy of  ship : 60 %\n",
      "Accuracy of truck : 72 %\n"
     ]
    }
   ],
   "source": [
    "# Inspect the accuracy on each labels\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels.cuda()).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
